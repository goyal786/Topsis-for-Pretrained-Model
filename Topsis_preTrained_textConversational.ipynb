{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def apply_topsis(matrix, criteria_weights):\n",
        "    # Normalize the decision matrix\n",
        "    norm_matrix = matrix / np.sqrt((matrix ** 2).sum(axis=0))\n",
        "\n",
        "    # Apply the weights to each criterion\n",
        "    weighted_matrix = norm_matrix * criteria_weights\n",
        "\n",
        "    # Identify the ideal and negative-ideal solutions\n",
        "    best_criteria = weighted_matrix.max(axis=0)  # Best for each criterion\n",
        "    worst_criteria = weighted_matrix.min(axis=0)  # Worst for each criterion\n",
        "\n",
        "    # Compute Euclidean distances\n",
        "    distance_to_best = np.sqrt(((weighted_matrix - best_criteria) ** 2).sum(axis=1))\n",
        "    distance_to_worst = np.sqrt(((weighted_matrix - worst_criteria) ** 2).sum(axis=1))\n",
        "\n",
        "    # Calculate the relative closeness score\n",
        "    closeness_score = distance_to_worst / (distance_to_best + distance_to_worst)\n",
        "\n",
        "    return closeness_score\n",
        "\n",
        "# Sample dataset: Evaluating AI models based on multiple criteria\n",
        "ai_models = ['GPT-4', 'Claude', 'Gemini', 'LLaMA', 'Mistral']\n",
        "score_matrix = np.array([\n",
        "    [9, 9, 8, 7, 9, 6],  # GPT-4\n",
        "    [8, 8, 7, 8, 8, 7],  # Claude\n",
        "    [8, 9, 8, 6, 8, 7],  # Gemini\n",
        "    [7, 7, 7, 7, 7, 8],  # LLaMA\n",
        "    [7, 8, 8, 8, 7, 9]   # Mistral\n",
        "])\n",
        "\n",
        "# Define the importance of each criterion (should sum to 1)\n",
        "criteria_weights = np.array([0.25, 0.2, 0.2, 0.15, 0.1, 0.1])\n",
        "\n",
        "# Compute the TOPSIS scores\n",
        "final_scores = apply_topsis(score_matrix, criteria_weights)\n",
        "\n",
        "# Rank the AI models based on scores\n",
        "ranked_results = pd.DataFrame({'Model': ai_models, 'Score': final_scores})\n",
        "ranked_results = ranked_results.sort_values(by='Score', ascending=False)\n",
        "\n",
        "# Display the final ranking\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7unYTzRPHIRZ",
        "outputId": "d85020e2-3705-439d-b086-54b612aeaf12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Model     Score\n",
            "0    GPT-4  0.667113\n",
            "2   Gemini  0.524808\n",
            "1   Claude  0.517930\n",
            "4  Mistral  0.482266\n",
            "3    LLaMA  0.269973\n"
          ]
        }
      ]
    }
  ]
}
